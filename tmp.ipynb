{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7600bd4-c626-47a2-ba4c-cb5f95099437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "from attributes_predictor_module.openai.schemas import GarmentDescription\n",
    "from dotenv import load_dotenv\n",
    "from PIL import ImageOps, Image\n",
    "load_dotenv()\n",
    "\n",
    "def encode_image_pil(pil_image):\n",
    "    buffered = io.BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "def resize_image_to_fit_larger_side(img, target_size):\n",
    "    original_width, original_height = img.size\n",
    "    if original_width > original_height:\n",
    "        new_width = target_size\n",
    "        new_height = int((target_size / original_width) * original_height)\n",
    "    else:\n",
    "        new_height = target_size\n",
    "        new_width = int((target_size / original_height) * original_width)\n",
    "\n",
    "    resized_image = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "    return resized_image\n",
    "\n",
    "def form_image_request_body(prompts, image):\n",
    "    base64_image = encode_image_pil(image)\n",
    "    request_body = [{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompts[\"system\"]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompts[\"user\"]},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    return request_body\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    ")\n",
    "\n",
    "# current_file_directory = os.path.dirname(os.path.abspath(__file__))\n",
    "# relative_path = os.path.join(current_file_directory, 'config.json')\n",
    "relative_path = \"/workspace/VTO_demo/attributes_predictor_module/openai/config.json\"\n",
    "with open(relative_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "def get_garment_description(image):\n",
    "    image = resize_image_to_fit_larger_side(image, config['image_size'])\n",
    "    messages = form_image_request_body(config['prompts'], image)\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        response_format=GarmentDescription,\n",
    "    )\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "500b2894-5c9a-4762-be85-dff77a3abf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('example/cloth/Long Sleeve Belted Wrap Coat in Dark Green with Stand Collar.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c54a877-c12d-4d88-941f-461dd257aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_garment_description(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d702aa9c-3bde-4247-92a0-c86bcd125b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
